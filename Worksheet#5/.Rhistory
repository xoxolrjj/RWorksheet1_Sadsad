html_text
ratings<-scrape(session)%>%
html_nodes('span.a-icon-alt')%>%
html_text
prices_ratings<-data.frame(prices[2:4],
ratings[2:4]
)
colnames(prices_ratings) <- c("Price", "Overall Rating");
teeback_urls<-c(
"https://www.amazon.com/TELALEO-Athletic-Racerback-Activewear-Sleeveless/dp/B08T1Z7FP1/ref=sr_1_5?crid=1OB1A9SM5CVRK&keywords=tee+back+tank+tops&qid=1701518421&sprefix=%2Caps%2C456&sr=8-5",#6, 5,or 3 pack
"https://www.amazon.com/Aeuui-Workout-Racerback-Shirts-Clothes/dp/B088CYZNKS/ref=sr_1_6?crid=1OB1A9SM5CVRK&keywords=tee+back+tank+tops&qid=1701518421&sprefix=%2Caps%2C456&sr=8-6",#Verdusa Women
"https://www.amazon.com/SOLY-HUX-Womens-Sleeveless-Shirts/dp/B0BYD8H1DZ/ref=sr_1_8?crid=1OB1A9SM5CVRK&keywords=tee+back+tank+tops&qid=1701518421&sprefix=%2Caps%2C456&sr=8-8"#SOLY HUX
)
all_reviews<-list()
for(url in teeback_urls){
page<-read_html(url)
user_comment<-page%>%html_nodes('span.a-size-base.review-text')%>%
html_text()
user_descr<-page%>%html_nodes('span.a-list-item.a-size-base.a-color-base')%>%
html_text()
user_comment_cleaned <- str_trim(user_comment[2:4])
reviews.df<-data.frame(user_comment_cleaned,
user_descr[2:4])
all_reviews[[url]]<-reviews.df
}
for(url in teeback_urls){
page<-read_html(url)
user_comment<-page%>%html_nodes('span.a-size-base.review-text')%>%
html_text()
user_descr<-page%>%html_nodes('span.a-list-item.a-size-base.a-color-base')%>%
html_text()
user_comment_cleaned <- str_trim(user_comment[2:4])
reviews.df<-data.frame(user_comment_cleaned,
user_descr[2:4])
all_reviews[[url]]<-reviews.df
}
colnames(reviews.df)<-c("Product Review", "Product Description")
do.call(rbind, reviews.df)
View(reviews.df)
final_amazon_scrape<-cbind(prices_ratings,reviews.df)
final_amazon_scrape
View(final_amazon_scrape)
library(tinytex)
install.packages("pgfplots")
install.packages("pgfplots")
install.packages("ggplot")
getwd()
pdflatex --enable-write18 --extra-mem-bot=10000000 --synctex=1 <RWorksheet#5_group(1&9).Rmd>
pdflatex --enable-write18 --extra-mem-bot=10000000 --synctex=1 <RWorksheet#5>
kpsewhich -a texmf.cnf
kpsewhich -a texmf.cnf
kpsewhich -a texmf.cnf
gc()
library(tinytex)
library(rvest)
library(httr)
library(dplyr)
library(polite)
library(stringr)
polite::use_manners(save_as = 'polite_scrape.R')
polite::use_manners(save_as = 'polite_scrape.R')
library(polite)
library(stringr)
polite::use_manners(save_as = 'polite_scrape.R')
library(polite)
library(stringr)
polite::use_manners(save_as = 'polite_scrape.R')
url <- 'https://m.imdb.com/chart/toptv/?ref_=nv_tvv_250'
session <- bow(url, user_agent = "Educational")
session <- bow(url, user_agent = "Educational")
session
title_show <- character(0)
polite::use_manners(save_as = 'polite_scrape.R')
library(rvest)
library(httr)
library(dplyr)
library(polite)
library(stringr)
polite::use_manners(save_as = 'polite_scrape.R')
install_tinytex()
sudo fmtutil-sys --all
library(Hmisc)
library(Hmisc)
library(pastecs)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
library(Hmisc)
library(Hmisc)
latticeExtra_0.6-28.tar
install.packages("htmltools")
install.packages("Hmisc")
install.packages("other_packages")
install.packages("other_package")
library(Hmisc)
library(Hmisc)
library(pastecs)
students_data <- data.frame (
Students = c(1:10),
preTest =  c(55,54,47,57,51,61,57,54,63,58),
postTest = c(61,60,56,63,56,63,59,56,62,61)
)
students_data
library(Hmisc)
library(pastecs)
students_data <- data.frame (
Students = c(1:10),
preTest =  c(55,54,47,57,51,61,57,54,63,58),
postTest = c(61,60,56,63,56,63,59,56,62,61)
)
students_data
View(students_data)
View(students_data)
stats_hmisc <- describe(students_data)
View(stats_hmisc)
stats_hmisc <- describe(students_data)
stats_pastics <- stat.desc(students_data)
View(students_data)
View(stats_pastics)
data_fertilize <- c(10,10,10, 20,20,50,10,20,10,50,20,50,20,10)
order(data_fertilize)
ordered(data_fertilize)
exerciseLevels<- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")
factor_exerciselevels<- factor(exerciseLevels)
levels(factor_exerciselevels) <- c("none","light","intense")
factor_exerciselevels
exercise_levels <- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")
exercise_factor <- factor(exercise_levels, levels = c("n", "l", "i"), labels = c("none", "light", "intense"))
exercise_factor
state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")
function(state)
state
factor(state)
with_factor_level <-factor(state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa") )
with_factor_level
incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)
incmeans <- tapply(incomes, factor_with_level, mean)
factor_with_level <-factor(state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa") )
factor_with_level
incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)
incmeans <- tapply(incomes, factor_with_level, mean)
incmeans
titles <- c("The Alchemist", "11 Minutes", "The Zahir", "The Valkyries")
pages <- c(197, 273, 320, 224)
books <- data.frame(titles,pages)
View(books)
titles[3]
result <- titles[c(3, length(titles))]
result
View(books)
x <- 20
y<- 10
prod_z = x*y
prod_z <- x*y
prod_z
prod_z = x*y
prod_z
participants <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
young_participants <- c(1, 3, 4, 7)
mid_participants <- c(2, 5, 6, 8)
old_participants <- c(9, 10, 11, 12)
Age <- factor(participants, levels = participants)
levels(Age) <- list(young = young_participants, mid = mid_participants, old = old_participants)
Age
participants <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)
young_participants <- c(1, 3, 4, 7)
mid_participants <- c(2, 5, 6, 8)
old_participants <- c(9, 10, 11, 12)
Age <- factor(participants, levels = participants)
Age
grade <- c(89, 90, 92, 85, 94)
# Create a pie chart with complete labels
pie(grade, labels = paste("Grade ", grade), main = "Distribution of Grades")
# Create a pie chart with complete labels
pie(grade, labels = paste("Grade ", grade), main = "Distribution of Grades", color = rainbow)
# Create a pie chart with complete labels
pie(grade, labels = paste("Grade ", grade), main = "Distribution of Grades", color = rainbow(grade))
grade <- c(89, 90, 92, 85, 94)
name <- c("Quiz1", "Quiz2", "Quiz3","Quiz4","Quiz5")
# Create a pie chart with complete labels
pie(grade,labels = name, main = "Distribution of Grades", rainbow(length(grade)))
name <- c("Quiz1", "Quiz2", "Quiz3","Quiz4","Quiz5")
# Create a pie chart with complete labels
pie(grade, labels = name, col = rainbow(length(grade)), main = "Distribution of Grades")
num1 <- c(1,2,3,4,5,6,7,8,9,10)
ifelse(x>5,x,0)
titles[c(3, length(titles))]
titles <- c("The Alchemist", "11 Minutes", "The Zahir", "The Valkyries")
titles[c(3, length(titles))]
#a. What is the standard error? Write the codes.
stdError <- function(x) sqrt(var(x)/length(x))
incster <- tapply(incomes, factor_with_level, stdError)
incster
students_score
students_score <- data.frame (
Students = c(1,2,3,4,5,6,7,8,9,10),
preTest =  c(55,54,47,57,51,61,57,54,63,58),
postTest = c(61,60,56,63,56,63,59,56,62,61)
)
#a. Compute the descriptive statistics using different packages (Hmisc and pastecs).Write the codes and its result
library(Hmisc)
library(pastecs)
stats_hmisc <- describe(students_data)
stats_hmisc <- describe(students_score)
stats_pastics <- stat.desc(students_score)
#a. Write the codes and describe the result.
order_fertilize <- c(10,10,10, 20,20,50,10,20,10,50,20,50,20,10)
ordered(order_fertilize)
exe_levels <- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")
exe_factor <- factor(exercise_levels, levels = c("n", "l", "i"), labels = c("none", "light", "intense"))
exe_levels <- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")
exe_factor <- factor(exe_levels, levels = c("n", "l", "i"), labels = c("none", "light", "intense"))
exe_factor
aussie_state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")
factor_with_level <-factor(aussie_state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa") )
factor_with_level
aussie_incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)
factor_and_level <-factor(aussie_state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa") )
factor_and_level
incmeans <- tapply(aussie_incomes, factor_and_level, mean)
incmeans
#a. What is the standard error? Write the codes.
stdErrors <- function(x) sqrt(var(x)/length(x))
incster <- tapply(incomes, factor_with_level, stdError)
#a. What is the standard error? Write the codes.
stdErrors <- function(x) sqrt(var(x)/length(x))
incster <- tapply(aussie_incomes, factor_and_level, stdError)
incster
#a. subset the titatic dataset of those who survived and not survived. Show the codes and its result.
library(datasets)
data(Titanic)
str(Titanic)
View(Titanic)
Titanic<-as.data.frame(Titanic)
not_subset_titanic <- subset(Titanic, Survived == "No")
not_subset_titanic
library(readr)
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
getwd)
getwd()
setwd("C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5")
library(readr)
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
breastcancer_wisconsin
summary(breastcancer_wisconsin)
#d. Compute the descriptive statistics using different packages. Find the values of:
#d.1 Standard error of the mean for clump thickness.
clump_thickness <- breastcancer_wisconsin$clump_thickness
#d. Compute the descriptive statistics using different packages. Find the values of:
#d.1 Standard error of the mean for clump thickness.
clumpthickness_dataset <- breastcancer_wisconsin$clump_thickness
stdError_clump_thickness <- stdError(clumpthickness_dataset)
stdError_clump_thickness
#d.2 Coefficient of variability for Marginal Adhesion.
marginaladhesion_data <- breastcancer_wisconsin$marginal_adhesion
mean <- mean(marginaladhesion_data)
#d.2 Coefficient of variability for Marginal Adhesion.
marginaladhesion_data <- breastcancer_wisconsin$marginal_adhesion
mean <- mean(marginaladhesion_data)
sd <- sd(marginaladhesion_data)
cv <- sd / mean
cv
cv<-cv*100 #Getting the percentage
cv
#d.3 Number of null values of Bare Nuclei.
barenuclei_data <- breastcancer_wisconsin$bare_nucleoli
num__values <- sum(is.na(barenuclei_data))
numNull__values <- sum(is.na(barenuclei_data))
numNull__values
#d. Compute the descriptive statistics using different packages. Find the values of:
#d.1 Standard error of the mean for clump thickness.
clumpThickness_dataset <- breastcancer_wisconsin$clump_thickness
stdError_clump_thickness <- stdError(clumpThickness_dataset)
stdError_clump_thickness
#d.2 Coefficient of variability for Marginal Adhesion.
marginalAdhesion_data <- breastcancer_wisconsin$marginal_adhesion
#d.2 Coefficient of variability for Marginal Adhesion.
marginalAdhesion_data <- breastcancer_wisconsin$marginal_adhesion
mean <- mean(marginalAdhesion_data)
sd <- sd(marginalAdhesion_data)
cv <- sd / mean
cv
cv<-cv*100 #getting the percentage
cv
#d.3 Number of null values of Bare Nuclei.
bareNuclei_data <- breastcancer_wisconsin$bare_nucleoli
numNull__values <- sum(is.na(bareNuclei_data))
numNull__values
bareNuclei_data
#d.3 Number of null values of Bare Nuclei.
bareNuclei_data <- breastcancer_wisconsin$bare_nucleoli
numNull__values <- sum(is.na(blandChromatin_data))
numNull__values
#d.4 Mean and standard deviation for Bland Chromatin
blandChromatin_data <- breastcancer_wisconsin$bland_chromatin
mean_blandChromatin <- mean(blandChromatin_data)
sd_blandChromatin <- sd(blandChromatin_data)
mean_blandChromatin
sd_blandChromatin
confidence_Interval <- t.test(shapeUniformity_data, na.rm = TRUE)$conf.int
#d.5 Confidence interval of the mean for Uniformity of Cell Shape
#Using t.test function
shapeUniformity_data <- breastcancer_wisconsin$shape_uniformity
confidence_Interval <- t.test(shapeUniformity_data, na.rm = TRUE)$conf.int
confidence_Interval
)
print(confidence_Interval)
#d. How many attributes?
length(breastcancer_wisconsin)
#d. How many attributes?
length(breastcancer_wisconsin)
names(breastcancer_wisconsin)
#e. Find the percentage of respondents who are malignant. Interpret the results
str(breastcancer_wisconsin)
View(breastcancer_wisconsin)
#e. Find the percentage of respondents who are malignant. Interpret the results
str(breastcancer_wisconsin)
View(breastcancer_wisconsin)
View(breastcancer_wisconsin)
percentage_malignant <- sum(breastcancer_wisconsin$class == 4) / nrow(breastcancer_wisconsin) * 100
percentage_malignant
#9. Export the data abalone to the Microsoft excel file. Copy the codes.
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
data("abalone")
View(abalone)
library("AppliedPredictiveModeling")
data("abalone")
View(abalone)
head(abalone)
summary(abalone)
getwd()
Abalone_excel<-"C:/Users/User/Documents/Rstudio Files/AbaloneData.xlsx"
install.packages("writexl")
Abalone_excel<-"C:/Users/User/Documents/Rstudio Files/AbaloneData.xlsx"
abalone_excel<-"C:/Users/User/Documents/Rstudio Files/AbaloneData.xlsx"
install.packages("writexl")
getwd()
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/AbaloneData.xlsx"
install.packages("writexl")
library(writexl)
write_xlsx(abalone, Abalone_excel)
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/AbaloneData.xlsx"
install.packages("writexl")
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/abaloneData.xlsx"
install.packages("writexl")
install.packages("writexl")
library(writexl)
write_xlsx(abalone, Abalone_excel)
#9. Export the data abalone to the Microsoft excel file. Copy the codes.
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
data("abalone")
View(abalone)
head(abalone)
summary(abalone)
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/abaloneData.xlsx"
install.packages("writexl")
install.packages("writexl")
library(writexl)
write_xlsx(abalone, Abalone_excel)
write_xlsx(abalone, abalone_excel)
students_score <- data.frame (
Students = c(1,2,3,4,5,6,7,8,9,10),
preTest =  c(55,54,47,57,51,61,57,54,63,58),
postTest = c(61,60,56,63,56,63,59,56,62,61)
)
#a. Compute the descriptive statistics using different packages (Hmisc and pastecs).Write the codes and its result
library(Hmisc)
#a. Compute the descriptive statistics using different packages (Hmisc and pastecs).Write the codes and its result
library(Hmisc)
library(pastecs)
stats_hmisc <- describe(students_score)
stats_pastics <- stat.desc(students_score)
#a. Write the codes and describe the result.
order_fertilize <- c(10,10,10, 20,20,50,10,20,10,50,20,50,20,10)
ordered(order_fertilize)
# a. What is the best way to represent this in R?
exe_levels <- c("l", "n", "n", "i", "l", "l", "n", "n", "i", "l")
exe_factor <- factor(exe_levels, levels = c("n", "l", "i"), labels = c("none", "light", "intense"))
exe_factor
aussie_state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")
factor_and_level <-factor(aussie_state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa"))
aussie_incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)
incmeans <- tapply(aussie_incomes, factor_and_level, mean)
#a. subset the titatic dataset of those who survived and not survived. Show the codes and its result.
library(datasets)
data(Titanic)
Titanic<-as.data.frame(Titanic)
subset_titanic<-subset(Titanic, Survived=="Yes")
not_subset_titanic <- subset(Titanic, Survived == "No")
library(readr)
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
breastcancer_wisconsin
summary(breastcancer_wisconsin)
#a. What is the standard error? Write the codes.
stdErrors <- function(x) sqrt(var(x)/length(x))
stdErrors
incster <- tapply(aussie_incomes, factor_and_level, stdError)
#a. What is the standard error? Write the codes.
stdErrors <- function(x) sqrt(var(x)/length(x))
stdErrors
incster <- tapply(aussie_incomes, factor_and_level, stdErrors)
incster
library(readr)
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
breastcancer_wisconsin
summary(breastcancer_wisconsin)
#d.1 Standard error of the mean for clump thickness.
clumpThickness_dataset <- breastcancer_wisconsin$clump_thickness
stdError_clump_thickness <- stdError(clumpThickness_dataset)
stdError_clump_thickness <- stdErrors(clumpThickness_dataset)
stdError_clump_thickness
#d. Compute the descriptive statistics using different packages. Find the values of:
#d.1 Standard error of the mean for clump thickness.
clumpThickness_dataset <- breastcancer_wisconsin$clump_thickness
stdError_clump_thickness <- stdErrors(clumpThickness_dataset)
stdError_clump_thickness
#d.1 Standard error of the mean for clump thickness.
clumpThickness_dataset <- breastcancer_wisconsin$clump_thickness
stdError_clump_thickness <- stdErrors(clumpThickness_dataset)
stdError_clump_thickness
#d.4 Mean and standard deviation for Bland Chromatin
blandChromatin_data <- breastcancer_wisconsin$bland_chromatin
mean_blandChromatin <- mean(blandChromatin_data)
sd_blandChromatin <- sd(blandChromatin_data)
mean_blandChromatin
sd_blandChromatin
#d.5 Confidence interval of the mean for Uniformity of Cell Shape
#Using t.test function
shapeUniformity_data <- breastcancer_wisconsin$shape_uniformity
confidence_Interval <- t.test(shapeUniformity_data, na.rm = TRUE)$conf.int
confidence_Interval
#d. How many attributes?
length(breastcancer_wisconsin)
names(breastcancer_wisconsin)
#e. Find the percentage of respondents who are malignant. Interpret the results
percentage_malignant <- sum(breastcancer_wisconsin$class == 4) / nrow(breastcancer_wisconsin) * 100
percentage_malignant
#Accordingly, the result 34.47783 indicates that roughly 34.48% of the participants in the dataset on breast cancer are categorized as malignant. The relative frequency of malignant cases in the dataset is shown by this percentage.
```
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
data("abalone")
View(abalone)
head(abalone)
summary(abalone)
summary(abalone)
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/abaloneData.xlsx"
install.packages("writexl")
summary(abalone)
abalone_excel<-"C:/Users/missy/OneDrive/Documents/Github/RWorksheets_Sadsad/Worksheet#5/abaloneData.xlsx"
install.packages("writexl")
library(writexl)
install.packages("writexl")
install.packages("writexl")
write_xlsx(abalone, abalone_excel)
mean_blandChromatin <- mean(blandChromatin_data)
sd_blandChromatin <- sd(blandChromatin_data)
mean_blandChromatin
summary(breastcancer_wisconsin)
library(readr)
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
breastcancer_wisconsin
summary(breastcancer_wisconsin)
#d.4 Mean and standard deviation for Bland Chromatin
blandChromatin_data <- breastcancer_wisconsin$bland_chromatin
mean_blandChromatin <- mean(blandChromatin_data)
sd_blandChromatin <- sd(blandChromatin_data)
mean_blandChromatin
sd_blandChromatin
bland_chromatin_data <- breastcancer_wisconsin$bland_chromatin
mean_bland_chromatin <- mean(bland_chromatin_data)
sd_bland_chromatin <- sd(bland_chromatin_data)
mean_bland_chromatin
sd_bland_chromatin
breastcancer_wisconsin$bland_chromatin
breastcancer_wisconsin
csv.file<-"breastcancer_wisconsin.csv"
breastcancer_wisconsin<-read.csv("breastcancer_wisconsin.csv")
breastcancer_wisconsin
View(breastcancer_wisconsin)
breastcancer_wisconsin$bland_chromatin
mean(bland_chromatin)
breastcancer_wisconsin$bland_chromatin
mean(bland_chromatin)
breastcancer_wisconsin$bland_chromatin
mean(breastcancer_wisconsin$bland_chromatin)
sd(breastcancer_wisconsin$bland_chromatin)
